import pandas as pd
import numpy as np
import time
import os


def data_cleaning_master(file_path, file_name):
    print("\nğŸ”° Welcome to the **Data Cleaning Master** Tool! ğŸ”°\n")
    time.sleep(2)
    
    print("ğŸ•µï¸ Starting the analysis...")
    time.sleep(1)

    if not os.path.exists(file_path):
        print("\nâŒ Invalid file path! Please double-check and try again.\n")
        return
    else:
        time.sleep(2)
        print(f"âœ… File path validated: {file_path}\n")
        time.sleep(1)

        if file_path.endswith('.csv'):
            print("ğŸ“‚ Dataset identified as a CSV file. Loading now...\n")
            time.sleep(2)
            df = pd.read_csv(file_path, encoding_errors='ignore')
        elif file_path.endswith('.xlsx'):
            print("ğŸ“‚ Dataset identified as an Excel file. Loading now...\n")
            time.sleep(2)
            df = pd.read_excel(file_path)
        else:
            print("\nâŒ Unknown file type! Supported formats are .csv and .xlsx only.\n")
            return

    print(f"âœ… Dataset loaded successfully!\n")
    time.sleep(2)

    # Showing number of records
    print(f"ğŸ” Initial analysis shows:\n- Total Rows: {df.shape[0]}\n- Total Columns: {df.shape[1]}\n")
    time.sleep(2)

    # Checking duplicates
    duplicates = df.duplicated()
    total_duplicates = duplicates.sum()

    print(f"ğŸ“Š Duplicate Record Check:\n- Total Duplicates: {total_duplicates}\n")
    time.sleep(2)

    # Saving the duplicates
    if total_duplicates > 0:
        duplicate_records_df = df[duplicates]
        duplicate_file = f"{file_name}_duplicates.csv"
        duplicate_records_df.to_csv(duplicate_file, index=False)
        print(f"âš ï¸ Duplicate records saved to: {duplicate_file}\n")
        time.sleep(2)

    df.drop_duplicates(inplace=True)
    print("ğŸ§¹ Duplicate records removed from the dataset.\n")
    time.sleep(1)

    # Find missing values
    total_missing_value = df.isnull().sum().sum()
    print(f"ğŸ” Missing Values Check:\n- Total Missing Values: {total_missing_value}\n")

    if total_missing_value > 0:
        print("âœ¨ Dealing with missing values column by column...\n")
    time.sleep(2)

    # Dealing with missing values
    columns = df.columns
    for col in columns:
        if df[col].dtype in (float, int):
            df[col] = df[col].fillna(df[col].mean())
            print(f"âœ… Filled missing values in column '{col}' with the column's mean.\n")
        else:
            df.dropna(subset=[col], inplace=True)
            print(f"âœ… Dropped rows with missing values in column '{col}'.\n")
        time.sleep(1)

    # Data is cleaned
    print("\nğŸ‰ **Congratulations! Your dataset is now clean!** ğŸ‰\n")
    print(f"- Cleaned Dataset Rows: {df.shape[0]}\n- Cleaned Dataset Columns: {df.shape[1]}\n")
    time.sleep(2)

    # Saving the clean dataset
    clean_file = f"{file_name}_clean_data.csv"
    df.to_csv(clean_file, index=False)
    print(f"ğŸ’¾ Cleaned dataset saved successfully to: {clean_file}\n")
    time.sleep(1)
    print("Thank you for using **Data Cleaning Master**. Have a great day! ğŸŒŸ\n")


if __name__ == "__main__":
    print("ğŸŒŸ Welcome to the **Data Cleaning Master** Tool! ğŸŒŸ\n")

    # Ask path and file name
    file_path = input("ğŸ“‚ Please enter the dataset path: ")
    file_name = input("ğŸ“ Please enter a name for the output files: ")

    # Calling the function
    data_cleaning_master(file_path, file_name)
